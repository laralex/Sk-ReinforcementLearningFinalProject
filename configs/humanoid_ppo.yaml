gym_env: 'Humanoid-v2'
timesteps_per_iteration: 2048
discount:                0.99
gae_discount:            0.95

# value function
critic:
  hidden_layers:    [64, 64]
  lr:               0.0001
  n_epochs:         10

trpo:
  kl_constraint:           Null
  fisher_estim_fraction:   Null
  conjugate_grad_steps:    Null
  conjugate_grad_damping:  Null
  backtracking_steps:      Null

actor:
  hidden_layers:    [64, 64]
  lr:               0.00015
  n_epochs:         10

ppo:
  clipping_epsilon: 0.2

code_level_opt:
  critic_loss_clpping:     True
  entropy_coefficient:     0.0
  reward_clipping:         [-10.0, 10.0]
  state_clipping:          [-10.0, 10.0]
  gradient_clipping_l2:       Null
  activation_func:         "tanh"
  layers_initialization:   "orthogonal"
  state_normalization:     True
  returns_normalization:   True
  rewards_normalization:   False
  actor_annealing_class:   "StepLR"
  actor_annealing_kwargs:
    step_size: 2
    gamma: 0.5
  critic_annealing_class:  "StepLR"
  critic_annealing_kwargs:
    step_size: 2
    gamma: 0.5



